# -*- coding: utf-8 -*-
"""Jackline Mpaye_Final Assesment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g7Kj27cGA3Ogh9AGf0x0LnjYK4DcS6jF

#libraries
"""

# Import necessary libraries
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, mean_squared_error
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.neural_network import MLPClassifier, MLPRegressor
from sklearn.svm import SVC, SVR
import joblib
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive

drive.mount('/content/drive')

"""# Data Loading Section"""

#Load training and test datasets. Replace 'train_data.csv' and 'test_data.csv' with actual file paths.
train_data = pd.read_csv('/content/drive/My Drive/Train_data.csv')
test_data = pd.read_csv('/content/drive/My Drive/Test_data.csv')



# Display basic info about the training data
train_data.info()

# Display basic info about the training data
test_data.info()

"""#Exploratory Data Analysis"""

# Basic statistics and visualization
print(train_data.describe())

"""# Task Identification"""

# Display the first few values of the target column to identify the type of task
print(train_data["class"].head())

# Display unique values of the target column to understand the problem better
print(train_data["class"].unique())

# Function to identify whether the task is classification or regression based on the target column
def identify_task(train_data, target_column):
    """
    Identifies the type of task (classification or regression) based on the target column.
    If the number of unique values in the target column is less than or equal to 10, it is classified as a classification task.
    """
    if train_data[target_column].nunique() <= 10:
        return "classification"
    return "regression"

# Define the target column and identify the task type
target_column = "class"
task_type = identify_task(train_data, target_column)
print(f"Identified Task: {task_type}")

"""# Feature Preprocessing"""

# Separate features and target, and identify categorical columns for encoding
features = [col for col in train_data.columns if col != target_column]


#categorical_columns = [col for col in train_data.select_dtypes(include=['object']).columns if col != target_column]
categorical_columns = train_data.select_dtypes(include=['object']).columns
categorical_columns = [col for col in categorical_columns if col != target_column]
print("Categorical Columns:", categorical_columns)

# Perform label encoding for categorical features

encoder = LabelEncoder()
if len(categorical_columns) > 0:
    for column in categorical_columns:
        combined_data = pd.concat([train_data[column], test_data[column]], axis=0)
        # Fit the encoder on the combined data
        encoder.fit(combined_data)

        # Transform the train and test data
        train_data[column] = encoder.transform(train_data[column])
        test_data[column] = encoder.transform(test_data[column])

numerical_columns = test_data.select_dtypes(include=['int64', 'float64']).columns
for col in numerical_columns:
    if not pd.api.types.is_numeric_dtype(test_data[col]):
        print(f"Column '{col}' contains non-numeric data. Converting or removing invalid entries...")
        # Convert non-numeric to NaN
        test_data[col] = pd.to_numeric(test_data[col], errors='coerce')

# Fill missing values introduced by non-numeric entries
test_data[numerical_columns] = test_data[numerical_columns].fillna(test_data[numerical_columns].mean())


test_data

"""# Data Splitting"""

# Split the training data into training and validation sets.

X = train_data.drop('class', axis=1)
y = train_data[target_column]
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Feature Scaling"""

# Standardize numerical features to improve model performance.
scaler = StandardScaler()
numerical_columns = train_data.select_dtypes(include=['int64', 'float64']).columns

print(numerical_columns)
for col in numerical_columns:
    if not pd.api.types.is_numeric_dtype(X_train[col]):
        print(f"Column '{col}' contains non-numeric data. Converting or removing invalid entries...")
        # Convert non-numeric to NaN
        X_train[col] = pd.to_numeric(X_train[col], errors='coerce')

# Fill missing values introduced by non-numeric entries
X_train[numerical_columns] = X_train[numerical_columns].fillna(X_train[numerical_columns].mean())


X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])
X_val[numerical_columns] = scaler.transform(X_val[numerical_columns])
test_data[numerical_columns] = scaler.transform(test_data[numerical_columns])

"""# Baseline Performance"""

# Compute a baseline performance metric to compare models against.
if task_type == "classification":
    most_common_label = y_train.mode()[0]
    baseline_predictions = [most_common_label] * len(y_val)
    baseline_score = accuracy_score(y_val, baseline_predictions)
    print(f"Baseline Accuracy: {baseline_score:.4f}")
else:
    baseline_prediction = y_train.mean()
    baseline_predictions = [baseline_prediction] * len(y_val)
    baseline_score = mean_squared_error(y_val, baseline_predictions, squared=False)
    print(f"Baseline RMSE: {baseline_score:.4f}")

"""# Model Selection and Training"""

# Define models for classification and regression tasks.
models = {
    "classification": [
        RandomForestClassifier(random_state=42),
        SVC(random_state=42, probability=True),
        MLPClassifier(random_state=42, max_iter=500)
    ],
    "regression": [
        RandomForestRegressor(random_state=42),
        SVR(),
        MLPRegressor(random_state=42, max_iter=500)
    ]
}

# Train models and select the best-performing one based on validation performance.
best_model = None
best_score = float('-inf') if task_type == "classification" else float('inf')

for model in models[task_type]:
    model.fit(X_train, y_train)
    y_val_pred = model.predict(X_val)

    if task_type == "classification":
        score = accuracy_score(y_val, y_val_pred)
        print(f"Model: {model.__class__.__name__}, Accuracy: {score:.4f}")
        if score > best_score:
            best_score = score
            best_model = model
    else:
        score = mean_squared_error(y_val, y_val_pred, squared=False)
        print(f"Model: {model.__class__.__name__}, RMSE: {score:.4f}")
        if score < best_score:
            best_score = score
            best_model = model

print(f"Best Model: {best_model.__class__.__name__}")

"""Model evaluation"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Compute and display the confusion matrix
conf_matrix = confusion_matrix(y_val, best_model.predict(X_val))
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=best_model.classes_)
disp.plot(cmap="Blues", values_format="d")
plt.title("Confusion Matrix")
plt.show()

# Test Data Predictions
# We predict on test data without a target column
test_predictions = best_model.predict(test_data[features])

# Save predictions for external evaluation
output = pd.DataFrame({"Id": test_data.index, "Predicted": test_predictions})
output.to_csv("test_predictions.csv", index=False)
print("Test predictions saved to 'test_predictions.csv'.")

"""# Model Deployment"""

# Make predictions on the test dataset using the best model.
test_predictions = best_model.predict(test_data)

# Save predictions to a CSV file
output = pd.DataFrame({"Id": test_data.index, "Predicted": test_predictions})
output.to_csv("test_predictions.csv", index=False)

"""# Save Best Model"""

# Save the best model to a file for future use.
joblib.dump(best_model, "best_model.pkl")